{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "ready\n"
     ]
    }
   ],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost\n",
    "%matplotlib\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                      \n",
    "                       'Zn Content (wt. %)',#0\n",
    "                      'Co Cotent (wt. %)',#1\n",
    "                      'Fe Cotent (wt. %)',#2\n",
    "                      'O Content (at. %)',#4\n",
    "                      'S Content (at. %)',#5\n",
    "                      'Content of Pyridinic Species (at. %)',#5\n",
    "                      'Content of Graphitic Species (at. %)',#6\n",
    "                      'Content of Oxidized Species (at. %)',#7\n",
    "                      'Raman ID/IG Ratio',#8\n",
    "                      'BET Surface Area (m2 g-1)',#9\n",
    "                      'Micropore Ratio',#10\n",
    "                      'Mesopore Ratio',#11\n",
    "                      'Catalyst Loading on RDE/RRDE(mg cm-2)',#12\n",
    "                      'HW_0.78'#the classification target#14\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:13]\n",
    "raw_power=raw_data.iloc[:,13]\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('Best Classifier:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    best_model=grid.best_estimator_\n",
    "    prediction_train=best_model.predict(X_train)\n",
    "    prediction_test=best_model.predict(X_test)\n",
    "    final_result=classification_report(y_test,prediction_test,output_dict=True)\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    ###########generating a figure##########\n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    rank = [index for index, value in sorted(list(enumerate(best_model.feature_importances_)), key=lambda x:x[1],reverse=True)]\n",
    "    name_list=[   \n",
    "                       'Zn Content (wt. %)',#0\n",
    "                      'Co Cotent (wt. %)',#1\n",
    "                      'Fe Cotent (wt. %)',#2\n",
    "                      'O Content (at. %)',#4\n",
    "                      'S Content (at. %)',#5\n",
    "                      'Content of Pyridinic Species (at. %)',#5\n",
    "                      'Content of Graphitic Species (at. %)',#6\n",
    "                      'Content of Oxidized Species (at. %)',#7\n",
    "                      'Raman ID/IG Ratio',#8\n",
    "                      'BET Surface Area (m2 g-1)',#9\n",
    "                      'Micropore Ratio',#10\n",
    "                      'Mesopore Ratio',#11\n",
    "                      'Catalyst Loading on RDE/RRDE(mg cm-2)',#12\n",
    "                      'Rotating Speed (rpm)'#13\n",
    "    ]\n",
    "    plt.bar(range(len(best_model.feature_importances_)), best_model.feature_importances_,color='rgb',tick_label=name_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('%s importance classification 0.78.png' %algorithm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {} Best Score: 0.6495276653171389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72        22\n",
      "           1       0.55      0.92      0.69        12\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.74      0.75      0.70        34\n",
      "weighted avg       0.79      0.71      0.71        34\n",
      "\n",
      "LightGBM\n",
      "[ 2 15 61 47  0 65 52 53 70 75 75 45 55 32]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6126855600539811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        22\n",
      "           1       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.81      0.83      0.81        34\n",
      "weighted avg       0.83      0.82      0.83        34\n",
      "\n",
      "XGBoost\n",
      "[0.01593158 0.01015779 0.01426379 0.02325905 0.0688468  0.02857259\n",
      " 0.02248417 0.0234479  0.01458369 0.05869116 0.03456058 0.01686661\n",
      " 0.02458215 0.6437521 ]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6651821862348178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87        22\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.85      0.89      0.85        34\n",
      "weighted avg       0.90      0.85      0.86        34\n",
      "\n",
      "CatBoost\n",
      "[ 2.04744795  2.15069424  7.00214855  6.62816314  0.28344346  9.5894701\n",
      "  6.29374459  6.28437765  8.69625601 13.87229501  8.25631683  7.86478093\n",
      " 10.73460096 10.29626058]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6180836707152497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83        22\n",
      "           1       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.78      0.80      0.79        34\n",
      "weighted avg       0.81      0.79      0.80        34\n",
      "\n",
      "GradientBoost\n",
      "[0.01420988 0.01261444 0.07406813 0.08760146 0.01100777 0.09654873\n",
      " 0.05152259 0.07883405 0.10045109 0.16549194 0.09087264 0.03643463\n",
      " 0.06700683 0.11333582]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.670310391363023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88        22\n",
      "           1       0.73      0.92      0.81        12\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.84      0.87      0.85        34\n",
      "weighted avg       0.87      0.85      0.86        34\n",
      "\n",
      "Random Forest\n",
      "[0.02529742 0.0214305  0.08533587 0.07076805 0.0118804  0.09037939\n",
      " 0.07462562 0.07494754 0.10748617 0.11465019 0.08608846 0.07704311\n",
      " 0.08979166 0.07027562]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6385964912280702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.77        22\n",
      "           1       0.59      0.83      0.69        12\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.74      0.76      0.73        34\n",
      "weighted avg       0.78      0.74      0.74        34\n",
      "\n",
      "Extra Tree\n",
      "[0.00887504 0.0297205  0.08448129 0.08707802 0.05344151 0.07769753\n",
      " 0.05604106 0.08178365 0.12924967 0.05078194 0.02663835 0.0719236\n",
      " 0.15662119 0.08566664]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6387314439946019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       104\n",
      "           1       1.00      1.00      1.00        87\n",
      "\n",
      "    accuracy                           1.00       191\n",
      "   macro avg       1.00      1.00      1.00       191\n",
      "weighted avg       1.00      1.00      1.00       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70        22\n",
      "           1       0.50      0.67      0.57        12\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.64      0.65      0.64        34\n",
      "weighted avg       0.68      0.65      0.65        34\n",
      "\n",
      "Decision Tree\n",
      "[0.         0.01876412 0.         0.06487467 0.04222552 0.12857256\n",
      " 0.13374387 0.10562044 0.09833045 0.19646143 0.02884547 0.00370706\n",
      " 0.0680827  0.1107717 ]\n",
      "start\n",
      "Best Classifier: {} Best Score: 0.6287449392712551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       104\n",
      "           1       0.91      0.89      0.90        87\n",
      "\n",
      "    accuracy                           0.91       191\n",
      "   macro avg       0.91      0.90      0.90       191\n",
      "weighted avg       0.91      0.91      0.91       191\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        22\n",
      "           1       0.69      0.75      0.72        12\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.77      0.78      0.78        34\n",
      "weighted avg       0.80      0.79      0.80        34\n",
      "\n",
      "AdaBoost\n",
      "[0.04 0.04 0.1  0.08 0.   0.12 0.02 0.12 0.1  0.08 0.04 0.08 0.14 0.04]\n"
     ]
    }
   ],
   "source": [
    "seed=117\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_param, raw_power, test_size=.15,random_state=seed)\n",
    "##########LGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMClassifier=lightgbm.LGBMClassifier(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "#  'boosting_type':['gbdt','rf'],\n",
    "#  'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "#  'n_estimators':[100,200,400,800],\n",
    "#  'subsample':[0.5,0.6,0.7,0.8,0.9,1],\n",
    "#  'reg_alpha':[0,0.001,0.01],\n",
    "#  'reg_lambda':[0,0.001,0.01]\n",
    "}\n",
    "gridsearch(model_LightGBMClassifier,param_light,'LightGBM')\n",
    "\n",
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBClassifier=xgboost.XGBClassifier(objective ='reg:squarederror',random_state=1,verbose=0)\n",
    "param_xg = {\n",
    "#  'booster':['gbtree'],\n",
    "#  'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "#  'n_estimators':[100,200,400,800],\n",
    "#  'max_depth':[5,7,9,11],\n",
    "#  'subsample':[0.5,0.6,0.7,0.8,0.9,1],\n",
    "#  'reg_alpha':[0,0.001,0.01],\n",
    "#  'reg_lambda':[0,0.001,0.01]\n",
    "}\n",
    "gridsearch(model_XGBClassifier,param_xg,'XGBoost')\n",
    "\n",
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatClassifier=catboost.CatBoostClassifier(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "#  'learning_rate':[0.01,0.05,0.1],\n",
    "#  'n_estimators':[200,400],\n",
    "#  'max_depth':[5,8,11],\n",
    "#  'subsample':[0.5,0.6,0.7,0.8,0.9,1]\n",
    "}\n",
    "gridsearch(model_CatClassifier,param_cat,'CatBoost')\n",
    "\n",
    "\n",
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingClassifier = ensemble.GradientBoostingClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "#  'learning_rate':[0.01,0.05,0.1],\n",
    "#  'n_estimators':[200,400],\n",
    "#  'criterion':['friedman_mse','mae','mse'],\n",
    "#  'max_features':['auto','sqrt','log2'],\n",
    "#  'loss':['deviance', 'exponential']\n",
    "}\n",
    "gridsearch(model_GradientBoostingClassifier,param_GB,'GradientBoost')\n",
    "\n",
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestClassifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "#      'n_estimators':[100,200,400,800],\n",
    "#      'criterion':['gini','entropy'],\n",
    "#      'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_RandomForestClassifier,param_RF,'Random Forest')\n",
    "\n",
    "\n",
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeClassifier = ExtraTreeClassifier(random_state=1)\n",
    "param_ET = {\n",
    "#         'max_depth':[5,7,9,11],\n",
    "#         'criterion' : ['gini','entropy'],\n",
    "#         'splitter' : [ \"best\",'random'],\n",
    "#         'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_ExtraTreeClassifier,param_ET,'Extra Tree')\n",
    "\n",
    "\n",
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeClassifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "param_DT = {\n",
    "#         'max_depth':[5,7,9,11],\n",
    "#         'criterion' : ['gini','entropy'],\n",
    "#         'splitter' : [ \"best\",'random'],\n",
    "#         'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_DecisionTreeClassifier,param_DT,'Decision Tree')\n",
    "\n",
    "\n",
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostClassifier = ensemble.AdaBoostClassifier(random_state=1)\n",
    "param_Ada = {\n",
    "#      'n_estimators':[50,100,200,400,800],\n",
    "#      'learning_rate':[0.01,0.02,0.05,0.1,0.2,1]\n",
    "}\n",
    "gridsearch(model_AdaBoostClassifier,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start\n",
    "Best Classifier: {} Best Score: 0.6495276653171389\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.59      0.72        22\n",
    "           1       0.55      0.92      0.69        12\n",
    "\n",
    "    accuracy                           0.71        34\n",
    "   macro avg       0.74      0.75      0.70        34\n",
    "weighted avg       0.79      0.71      0.71        34\n",
    "\n",
    "LightGBM\n",
    "[ 2 15 61 47  0 65 52 53 70 75 75 45 55 32]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6126855600539811\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.82      0.86        22\n",
    "           1       0.71      0.83      0.77        12\n",
    "\n",
    "    accuracy                           0.82        34\n",
    "   macro avg       0.81      0.83      0.81        34\n",
    "weighted avg       0.83      0.82      0.83        34\n",
    "\n",
    "XGBoost\n",
    "[0.01593158 0.01015779 0.01426379 0.02325905 0.0688468  0.02857259\n",
    " 0.02248417 0.0234479  0.01458369 0.05869116 0.03456058 0.01686661\n",
    " 0.02458215 0.6437521 ]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6651821862348178\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.77      0.87        22\n",
    "           1       0.71      1.00      0.83        12\n",
    "\n",
    "    accuracy                           0.85        34\n",
    "   macro avg       0.85      0.89      0.85        34\n",
    "weighted avg       0.90      0.85      0.86        34\n",
    "\n",
    "CatBoost\n",
    "[ 2.04744795  2.15069424  7.00214855  6.62816314  0.28344346  9.5894701\n",
    "  6.29374459  6.28437765  8.69625601 13.87229501  8.25631683  7.86478093\n",
    " 10.73460096 10.29626058]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6180836707152497\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.77      0.83        22\n",
    "           1       0.67      0.83      0.74        12\n",
    "\n",
    "    accuracy                           0.79        34\n",
    "   macro avg       0.78      0.80      0.79        34\n",
    "weighted avg       0.81      0.79      0.80        34\n",
    "\n",
    "GradientBoost\n",
    "[0.01420988 0.01261444 0.07406813 0.08760146 0.01100777 0.09654873\n",
    " 0.05152259 0.07883405 0.10045109 0.16549194 0.09087264 0.03643463\n",
    " 0.06700683 0.11333582]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.670310391363023\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.82      0.88        22\n",
    "           1       0.73      0.92      0.81        12\n",
    "\n",
    "    accuracy                           0.85        34\n",
    "   macro avg       0.84      0.87      0.85        34\n",
    "weighted avg       0.87      0.85      0.86        34\n",
    "\n",
    "Random Forest\n",
    "[0.02529742 0.0214305  0.08533587 0.07076805 0.0118804  0.09037939\n",
    " 0.07462562 0.07494754 0.10748617 0.11465019 0.08608846 0.07704311\n",
    " 0.08979166 0.07027562]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6385964912280702\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.68      0.77        22\n",
    "           1       0.59      0.83      0.69        12\n",
    "\n",
    "    accuracy                           0.74        34\n",
    "   macro avg       0.74      0.76      0.73        34\n",
    "weighted avg       0.78      0.74      0.74        34\n",
    "\n",
    "Extra Tree\n",
    "[0.00887504 0.0297205  0.08448129 0.08707802 0.05344151 0.07769753\n",
    " 0.05604106 0.08178365 0.12924967 0.05078194 0.02663835 0.0719236\n",
    " 0.15662119 0.08566664]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6387314439946019\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00       104\n",
    "           1       1.00      1.00      1.00        87\n",
    "\n",
    "    accuracy                           1.00       191\n",
    "   macro avg       1.00      1.00      1.00       191\n",
    "weighted avg       1.00      1.00      1.00       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.78      0.64      0.70        22\n",
    "           1       0.50      0.67      0.57        12\n",
    "\n",
    "    accuracy                           0.65        34\n",
    "   macro avg       0.64      0.65      0.64        34\n",
    "weighted avg       0.68      0.65      0.65        34\n",
    "\n",
    "Decision Tree\n",
    "[0.         0.01876412 0.         0.06487467 0.04222552 0.12857256\n",
    " 0.13374387 0.10562044 0.09833045 0.19646143 0.02884547 0.00370706\n",
    " 0.0680827  0.1107717 ]\n",
    "start\n",
    "Best Classifier: {} Best Score: 0.6287449392712551\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.92      0.91       104\n",
    "           1       0.91      0.89      0.90        87\n",
    "\n",
    "    accuracy                           0.91       191\n",
    "   macro avg       0.91      0.90      0.90       191\n",
    "weighted avg       0.91      0.91      0.91       191\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.82      0.84        22\n",
    "           1       0.69      0.75      0.72        12\n",
    "\n",
    "    accuracy                           0.79        34\n",
    "   macro avg       0.77      0.78      0.78        34\n",
    "weighted avg       0.80      0.79      0.80        34\n",
    "\n",
    "AdaBoost\n",
    "[0.04 0.04 0.1  0.08 0.   0.12 0.02 0.12 0.1  0.08 0.04 0.08 0.14 0.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
