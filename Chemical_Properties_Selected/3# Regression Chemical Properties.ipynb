{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=sum(absError)/len(absError)\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                      'Fe Cotent (wt. %)',#2\n",
    "                      'O Content (at. %)',#4\n",
    "                      'Content of Pyridinic Species (at. %)',#5\n",
    "                      'Raman ID/IG Ratio',#8\n",
    "                      'BET Surface Area (m2 g-1)',#9\n",
    "                      'Micropore Ratio',#10\n",
    "                      'Mesopore Ratio',#11\n",
    "                      'Catalyst Loading on RDE/RRDE(mg cm-2)',#12\n",
    "                      'Half Wave Potential in Acid Condition (vs. RHE)'#the classification target#7\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:8]\n",
    "raw_power=raw_data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    result = best_model.predict(X_test)\n",
    "    x_prediction_07=result\n",
    "    y_real_07=y_test_values\n",
    "    x_prediction_07_series=pd.Series(x_prediction_07)\n",
    "    y_real_07_series=pd.Series(y_real_07)\n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_07_series.corr(y_real_07_series), 5)\n",
    "    error_val= compute_mae_mse_rmse(x_prediction_07,y_real_07)\n",
    "    rank = [index for index, value in sorted(list(enumerate(best_model.feature_importances_)), key=lambda x:x[1],reverse=True)]\n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    print(error_val)\n",
    "    print(corr_ann)\n",
    "    x_y_x=np.arange(0.5,1,0.1)\n",
    "    x_y_y=np.arange(0.5,1,0.1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_07,y_real_07,color='red',label=algorithm_name)\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Half_Wave_Potential V (vs. RHE)\")\n",
    "    plt.ylabel(u\"Real_Half_Wave_Potential V (vs. RHE)\")\n",
    "    plt.savefig('%s scatters.png' %algorithm_name)\n",
    "    fig2 = plt.figure()\n",
    "    name_list=[   \n",
    "                  'Fe Cotent (wt. %)',#2\n",
    "                      'O Content (at. %)',#4\n",
    "                      'Content of Pyridinic Species (at. %)',#5\n",
    "                      'Raman ID/IG Ratio',#8\n",
    "                      'BET Surface Area (m2 g-1)',#9\n",
    "                      'Micropore Ratio',#10\n",
    "                      'Mesopore Ratio',#11\n",
    "                      'Catalyst Loading on RDE/RRDE(mg cm-2)',#12\n",
    "    ]\n",
    "    plt.bar(range(len(best_model.feature_importances_)), best_model.feature_importances_,color='rgb',tick_label=name_list)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig('%s importance.png' %algorithm_name)\n",
    "    plt.show()\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=71\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_param, raw_power, test_size=.15,random_state=seed)\n",
    "y_test_values=y_test.values.astype(np.float32)\n",
    "\n",
    "##########LGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMRegressor=lightgbm.LGBMRegressor(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "    'boosting_type':['gbdt','rf'],\n",
    "    'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "    'n_estimators':[100,200,400,800],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'reg_alpha':[0,0.001,0.01],\n",
    "    'reg_lambda':[0,0.001,0.01] \n",
    "}\n",
    "gridsearch(model_LightGBMRegressor,param_light,'LightGBM')\n",
    "\n",
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBRegressor=xgboost.XGBRegressor(objective='reg:squarederror',random_state=1,verbose=0)\n",
    "param_xg = {\n",
    "    'booster':['gbtree'],\n",
    "    'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "    'n_estimators':[100,200,400,800],\n",
    "    'max_depth':[5,7,9,11],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9,1],\n",
    "    'reg_alpha':[0,0.001,0.01],\n",
    "    'reg_lambda':[0,0.001,0.01]\n",
    "}\n",
    "gridsearch(model_XGBRegressor,param_xg,'XGBoost')\n",
    "\n",
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatRegressor=catboost.CatBoostRegressor(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "    'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "    'n_estimators':[100,200,400,800],\n",
    "    'max_depth':[5,7,9,11],\n",
    "    'subsample':[0.5,0.6,0.7,0.8,0.9,1]\n",
    "}\n",
    "gridsearch(model_CatRegressor,param_cat,'CatBoost')\n",
    "\n",
    "\n",
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "            'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "            'n_estimators':[100,200,400,800],\n",
    "            'criterion':['friedman_mse','mae','mse'],\n",
    "             'max_features':['auto','sqrt','log2'],\n",
    "             'loss':['ls', 'lad', 'huber', 'quantile']\n",
    "}\n",
    "gridsearch(model_GradientBoostingRegressor,param_GB,'GradientBoost')\n",
    "\n",
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "                'n_estimators':[100,200,400,800],\n",
    "        'criterion':['mse','mae'],\n",
    "        'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_RandomForestRegressor,param_RF,'Random Forest')\n",
    "\n",
    "\n",
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeRegressor = ExtraTreeRegressor(random_state=1)\n",
    "param_ET = {\n",
    "                   'max_depth':[5,7,9,11],\n",
    "           'max_features':['auto','sqrt','log2'],\n",
    "           'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "           'splitter' : [ \"best\",'random']\n",
    "}\n",
    "gridsearch(model_ExtraTreeRegressor,param_ET,'Extra Tree')\n",
    "\n",
    "\n",
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor(random_state=1)\n",
    "param_DT = {\n",
    "                   'max_depth':[5,7,9,11],\n",
    "           'max_features':['auto','sqrt','log2'],\n",
    "           'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "           'splitter' : [ \"best\",'random']\n",
    "}\n",
    "gridsearch(model_DecisionTreeRegressor,param_DT,'Decision Tree')\n",
    "\n",
    "\n",
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(random_state=1)\n",
    "param_Ada = {\n",
    "                'n_estimators':[50,100,200,400,800],\n",
    "        'learning_rate':[0.01,0.02,0.05,0.1,0.2,1],\n",
    "        'loss':['linear', 'square', 'exponential']\n",
    "}\n",
    "gridsearch(model_AdaBoostRegressor,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
